{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VASP data aggregation example\n",
    "This is a tutorial on how to aggregate and collate information from VASP runs into a pandas dataframe using the crystaltools package.\n",
    "\n",
    "### Setup:\n",
    "Ugur Aydin's high throughput calculation of solution enthalpy has been preprocessed and stored as hdf5 files in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "import crystaltools.vasprun_parser as vp\n",
    "import crystaltools.fetch_tools as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define aggregate function\n",
    "\n",
    "Here, we will be using vasprun_parser, which take a list of file paths and an aggregating function as arguments to build the dataframe.\n",
    "\n",
    "- list of directories: We facilitate the construction of the list using the get_path_list function in fetch_tools.\n",
    "- aggregating function: We define this function below.  Since people generally want different sets of information from the VASP calculation, this function will be constructed by hand.  However, once defined, you can apply this function to all the hdf5 files (13299 files in this case). This function should have a file path as argument and return a pandas series.\n",
    "\n",
    "For the aggregating function, one can pull the information out manually using cElementTree.  However, pulling out information from the hdf5 file is facilited here by the VasprunHDFParser class in vasp_parser.  This class has convenient methods that return pieces of the VASP calculation. See docstring for details (help(vp.VasprunHDFParser)).\n",
    "\n",
    "For the aggregating function *aggregate_vasp_data*, we would be collecting:\n",
    "\n",
    "- el1, el2 - Primary and secondary elements\n",
    "- n1, n2 - number of each element above\n",
    "- isif - ISIF parameter (to determine if ions are allowed to move)\n",
    "- encut - ENCUT parameter\n",
    "- e_0_energy, e_fr_energy, e_wo_entrp - final energies of the calculation\n",
    "- volume - volume of the calculation cell\n",
    "- kx, ky, kz - kpoints\n",
    "- cubic - True if the calculation cell is cublic, else False\n",
    "- conv - True if the calculation has converged, else False\n",
    "- path - path of the h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregate_vasp_data(file_path):\n",
    "    \"\"\"\n",
    "        Aggregates data from h5 vasprun file defined by file_path.\n",
    "        Aggregated information are as follows:\n",
    "            el1, el2 - Primary and secondary elements\n",
    "            n1, n2 - number of each element above\n",
    "            isif - ISIF parameter (to determine if ions are allowed to move)\n",
    "            encut - ENCUT parameter\n",
    "            e_0_energy, e_fr_energy, e_wo_entrp - final energies of the calculation\n",
    "            volume - volume of the calculation cell\n",
    "            kx, ky, kz - kpoints\n",
    "            cubic - True if the calculation cell is cublic, else False\n",
    "            conv - True if the calculation has converged, else False\n",
    "            path - path of the h5 file\n",
    "            \n",
    "        :params:\n",
    "            file_path - file path of h5 file\n",
    " \n",
    "        :return:\n",
    "            pd.Series\n",
    "    \"\"\"\n",
    "    \n",
    "    with vp.VasprunHDFParser(directory='', filename=file_path) as vasprun:\n",
    "        # get element names and their number\n",
    "        atomtypes = vasprun.get_atomtypes()\n",
    "\n",
    "        el1 = atomtypes.index[0]\n",
    "        n1 = atomtypes.ix[0].atomspertype\n",
    "\n",
    "        if len(atomtypes)==2:\n",
    "            el2 = atomtypes.index[1]\n",
    "            n2 = atomtypes.ix[1].atomspertype\n",
    "        elif len(atomtypes)==1:\n",
    "            el2 = np.nan\n",
    "            n2 = np.nan\n",
    "        elif len(atomtypes)>2:\n",
    "            print('WARNING! MORE THAN 2 ELEMENTS FOUND!')\n",
    "\n",
    "        elements = pd.Series([el1, el2, n1, n2], index=['el1', 'el2', 'n1', 'n2'])\n",
    "\n",
    "        # get ISIF parameter\n",
    "        incar = vasprun.get_incar()\n",
    "        if 'ISIF' in incar.keys():\n",
    "            isif = incar.ISIF\n",
    "        else:\n",
    "            isif = 2\n",
    "        isif = pd.Series(isif, index=['isif'])\n",
    "\n",
    "        # get ENCUT parameter\n",
    "        if 'ENCUT' in incar.keys():\n",
    "            encut = incar.ENCUT\n",
    "        else:\n",
    "            encut = np.nan\n",
    "        encut = pd.Series(encut, index=['encut'])\n",
    "\n",
    "        # get energies\n",
    "        energies = vasprun.get_energies()\n",
    "        energies = pd.Series(energies.as_matrix()[-1,:], index=energies.columns)\n",
    "\n",
    "        # get volume\n",
    "        volume = vasprun.get_volume()\n",
    "\n",
    "        # get kpoints\n",
    "        kpts = vasprun.get_kpt_division()\n",
    "\n",
    "        # get cell vectors\n",
    "        cv = vasprun.get_cell_vectors()\n",
    "        v1 = cv[0,:]\n",
    "        v2 = cv[1,:]\n",
    "        v3 = cv[2,:]\n",
    "        cellvec = pd.Series([v1, v2, v3], index=['v1', 'v2', 'v3'])\n",
    "\n",
    "        # check if cubic\n",
    "        if (np.linalg.norm(v1)==np.linalg.norm(v2))\\\n",
    "          &(np.linalg.norm(v1)==np.linalg.norm(v3))\\\n",
    "          &(np.linalg.norm(v2)==np.linalg.norm(v3))\\\n",
    "          &(np.dot(v1,v2)==0)&(np.dot(v1,v3)==0)&(np.dot(v2,v3)==0):\n",
    "            cubic = pd.Series(True, index=['cubic'])\n",
    "        else:\n",
    "            cubic = pd.Series(False, index=['cubic'])\n",
    "\n",
    "        # check if calculation converged\n",
    "        if 'finalpos' in vasprun.root._v_children:\n",
    "            conv = pd.Series(True, index=['conv'])\n",
    "        else:\n",
    "            conv = pd.Series(False, index=['conv'])\n",
    "\n",
    "        # store series path\n",
    "        path = pd.Series(file_path, index=['path'])\n",
    "    \n",
    "        return pd.concat([elements, isif, energies, volume, kpts, encut,\n",
    "                          cubic, cellvec, conv, path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of file paths\n",
    "The ft.get_file_path takes the root path and a pattern as arguments.  It will look for all files matching the pattern that can be seen from the root path.  In this case, we want all files starting with vasprun and ends with h5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_path = '\\Volume\\Elements\\python\\aydin'\n",
    "pattern = re.compile('vasprun\\w+.h5', re.IGNORECASE)\n",
    "path_list = ft.get_path_list(root_path, pattern)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply aggregate_vasp_data to all files in path_list and construct the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 731 µs, sys: 68 µs, total: 799 µs\n",
      "Wall time: 768 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df, bad_path = ft.get_aggregate_data(aggregate_vasp_data, path_list, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect dataframe\n",
    "\n",
    "Processing and aggregating data from 13299 hdf5 files took 14min 13s on my humble MacBook Air, which is not bad.  It would probably be faster if we weren't checking if the cell was cubic.  Now we can inspect and interrogate the data will the full power of pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'el2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2e63ce8c6ab0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mel2\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'H '\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/dagatkarimlan/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2148\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m             raise AttributeError(\"'%s' object has no attribute '%s'\" %\n\u001b[0;32m-> 2150\u001b[0;31m                                  (type(self).__name__, name))\n\u001b[0m\u001b[1;32m   2151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'el2'"
     ]
    }
   ],
   "source": [
    "df[df.el2=='H '].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the dataframe in serial format for further analysis\n",
    "\n",
    "From here, we can easily store the summarized data into a serialed format like json or xml.  I choose json in this instance.  The resulting json file is under 4MB, and can easily be transfered out of, say, the comput cluster and worked on locally on a pc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_json('aydin_data_summary.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docstrings of classes and functions used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(vp.VasprunHDFParser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(ft.get_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(ft.get_aggregate_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
